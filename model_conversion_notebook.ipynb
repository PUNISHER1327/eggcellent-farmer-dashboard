{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Conversion for Supabase Edge Functions\n",
    "\n",
    "This notebook converts your Keras model and pickle scalers to TensorFlow.js format and JSON.\n",
    "\n",
    "## Steps:\n",
    "1. Upload your files: `purair_model.keras`, `scaler_X.pkl`, `scaler_y.pkl`\n",
    "2. Run all cells\n",
    "3. Download the converted files\n",
    "4. Upload them to Supabase Storage in the `models` bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflowjs tensorflow scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your files\n",
    "print(\"Please upload: purair_model.keras, scaler_X.pkl, scaler_y.pkl\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Keras model\n",
    "print(\"Loading Keras model...\")\n",
    "model = tf.keras.models.load_model('purair_model.keras')\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Get input shape\n",
    "input_shape = model.input_shape\n",
    "print(f\"\\nInput shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Rebuild model with explicit input shape\n",
    "# This ensures the model works properly in TensorFlow.js\n",
    "\n",
    "print(\"Rebuilding model with explicit input shape...\")\n",
    "\n",
    "# Create new model with explicit input layer\n",
    "new_model = tf.keras.Sequential()\n",
    "\n",
    "# Add input layer with explicit shape [1, 3] for LSTM\n",
    "# (1 timestep, 3 features: temperature, humidity, air_quality)\n",
    "new_model.add(tf.keras.layers.InputLayer(input_shape=(1, 3), batch_size=1))\n",
    "\n",
    "# Copy all layers except the first one if it's InputLayer\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i == 0 and isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        continue\n",
    "    new_model.add(layer)\n",
    "\n",
    "# Copy weights\n",
    "new_model.set_weights(model.get_weights())\n",
    "\n",
    "# Compile\n",
    "new_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model = new_model\n",
    "print(\"\\nRebuilt Model Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model works\n",
    "print(\"\\nTesting model with sample input...\")\n",
    "sample_input = np.array([[[25.0, 60.0, 45.0]]])  # shape: (1, 1, 3)\n",
    "prediction = model.predict(sample_input, verbose=0)\n",
    "print(f\"Sample prediction: {prediction[0][0]}\")\n",
    "print(\"Test successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TensorFlow.js format\n",
    "print(\"\\nConverting model to TensorFlow.js format...\")\n",
    "tfjs_output_dir = 'tfjs_model'\n",
    "\n",
    "# Remove old directory if exists\n",
    "if os.path.exists(tfjs_output_dir):\n",
    "    shutil.rmtree(tfjs_output_dir)\n",
    "\n",
    "# Convert\n",
    "tfjs.converters.save_keras_model(model, tfjs_output_dir)\n",
    "print(f\"Model converted successfully to {tfjs_output_dir}\")\n",
    "\n",
    "# List generated files\n",
    "print(\"\\nGenerated files:\")\n",
    "for file in os.listdir(tfjs_output_dir):\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaler_X.pkl to JSON\n",
    "print(\"\\nConverting scaler_X...\")\n",
    "with open('scaler_X.pkl', 'rb') as f:\n",
    "    scaler_X = pickle.load(f)\n",
    "\n",
    "scaler_X_dict = {\n",
    "    'mean': scaler_X.mean_.tolist(),\n",
    "    'scale': scaler_X.scale_.tolist()\n",
    "}\n",
    "\n",
    "with open('scaler_X.json', 'w') as f:\n",
    "    json.dump(scaler_X_dict, f, indent=2)\n",
    "\n",
    "print(\"scaler_X.json created\")\n",
    "print(f\"  Mean: {scaler_X_dict['mean']}\")\n",
    "print(f\"  Scale: {scaler_X_dict['scale']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaler_y.pkl to JSON\n",
    "print(\"\\nConverting scaler_y...\")\n",
    "with open('scaler_y.pkl', 'rb') as f:\n",
    "    scaler_y = pickle.load(f)\n",
    "\n",
    "scaler_y_dict = {\n",
    "    'mean': scaler_y.mean_.tolist(),\n",
    "    'scale': scaler_y.scale_.tolist()\n",
    "}\n",
    "\n",
    "with open('scaler_y.json', 'w') as f:\n",
    "    json.dump(scaler_y_dict, f, indent=2)\n",
    "\n",
    "print(\"scaler_y.json created\")\n",
    "print(f\"  Mean: {scaler_y_dict['mean']}\")\n",
    "print(f\"  Scale: {scaler_y_dict['scale']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file with all converted files\n",
    "print(\"\\nCreating zip file...\")\n",
    "!cd tfjs_model && zip -r ../converted_model.zip .\n",
    "!zip -u converted_model.zip scaler_X.json scaler_y.json\n",
    "print(\"converted_model.zip created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files\n",
    "print(\"\\nDownloading files...\")\n",
    "print(\"Downloading zip file (contains all files)...\")\n",
    "files.download('converted_model.zip')\n",
    "print(\"\\nAlso downloading individual files for direct upload...\")\n",
    "files.download('scaler_X.json')\n",
    "files.download('scaler_y.json')\n",
    "for file in os.listdir('tfjs_model'):\n",
    "    files.download(f'tfjs_model/{file}')\n",
    "print(\"\\nâœ… All files downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "1. **Delete old files from Supabase Storage** (important!):\n",
    "   - Go to: https://supabase.com/dashboard/project/ipfqxgzylmfyffeqpdrb/storage/buckets/models\n",
    "   - Delete all existing files\n",
    "\n",
    "2. **Upload new files to Supabase Storage:**\n",
    "   - Upload these files to the `models` bucket:\n",
    "     - `model.json`\n",
    "     - `group1-shard1of1.bin` (or similar .bin files)\n",
    "     - `scaler_X.json`\n",
    "     - `scaler_y.json`\n",
    "\n",
    "3. **Test the edge function** - It will automatically use these files!\n",
    "\n",
    "**IMPORTANT:** Make sure all files are in the root of the `models` bucket, not in a subfolder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
